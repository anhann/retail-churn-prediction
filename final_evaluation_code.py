# -*- coding: utf-8 -*-
"""Final evaluation code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1e0MdYBMjae-kPTkUHmH1YhHBV1olJgTh
"""

#import library
import psycopg2
import numpy as np
import pandas as pd
import tslearn as tl
from getpass import getpass
import matplotlib.pyplot as plt
import seaborn as sns

################################
#### CHANGE TO YOUR DETAILS ####
user = 'lixan23'
db_ip = '10.158.72.112'
################################
pw = getpass('Enter the database password for {}: '.format(user))

"""## Feature generation"""

# Commented out IPython magic to ensure Python compatibility.
# ref date (date for X - only take the people who not yet churn)
def get_dataset( reference_day, tumbling_window_size = 38, output_window_size = 38 ):
    with psycopg2.connect("host='{}' dbname='nlab' user='{}' password='{}'".format(db_ip, user, pw)) as conn:
      sql = """
      WITH 
      tumbling AS(
      SELECT customer_id,
#              %(ref_date)s::date AS ref_day,
             COUNT (DISTINCT CASE WHEN purchased_at > %(ref_date)s::DATE AND purchased_at <= %(ref_date)s::DATE + %(ows)s THEN purchased_at::DATE ELSE null END) as output_feature,
             SUM(CASE WHEN purchased_at > %(ref_date)s::DATE -%(ws)s AND purchased_at <= %(ref_date)s::DATE THEN value ELSE 0 END) as sale_f1,
             SUM(CASE WHEN purchased_at > %(ref_date)s::DATE -%(ws)s*2 AND purchased_at <= %(ref_date)s::DATE-%(ws)s THEN value ELSE 0 END ) as sale_f2,
             SUM(CASE WHEN purchased_at > %(ref_date)s::DATE -%(ws)s*3 AND purchased_at <= %(ref_date)s::DATE-%(ws)s*2 THEN value ELSE 0 END ) as sale_f3,
             SUM(CASE WHEN purchased_at > %(ref_date)s::DATE -%(ws)s*4 AND purchased_at <= %(ref_date)s::DATE-%(ws)s*3 THEN value ELSE 0 END ) as sale_f4,
             SUM(CASE WHEN purchased_at > %(ref_date)s::DATE -%(ws)s*5 AND purchased_at <= %(ref_date)s::DATE-%(ws)s*4 THEN value ELSE 0 END ) as sale_f5,
             COUNT (DISTINCT CASE WHEN purchased_at > %(ref_date)s::DATE -%(ws)s AND purchased_at <= %(ref_date)s::DATE THEN purchased_at::DATE ELSE null END ) as visit_f1,
             COUNT (DISTINCT CASE WHEN purchased_at > %(ref_date)s::DATE -%(ws)s*2 AND purchased_at <= %(ref_date)s::DATE-%(ws)s THEN purchased_at::DATE ELSE null END ) as visit_f2,
             COUNT (DISTINCT CASE WHEN purchased_at > %(ref_date)s::DATE -%(ws)s*3 AND purchased_at <= %(ref_date)s::DATE-%(ws)s*2 THEN purchased_at::DATE ELSE null END ) as visit_f3,
             COUNT (DISTINCT CASE WHEN purchased_at > %(ref_date)s::DATE -%(ws)s*4 AND purchased_at <= %(ref_date)s::DATE-%(ws)s*3 THEN purchased_at::DATE ELSE null END ) as visit_f4,
             COUNT (DISTINCT CASE WHEN purchased_at > %(ref_date)s::DATE -%(ws)s*5 AND purchased_at <= %(ref_date)s::DATE-%(ws)s*4 THEN purchased_at::DATE ELSE null END ) as visit_f5
     FROM ml2.receipts_clean
     JOIN ml2.receipt_lines_clean
     USING (receipt_id)
     GROUP BY customer_id),
     
     rfm AS (
     SELECT customer_id,
             SUM(value) as total_spend,
             COUNT (DISTINCT purchased_at::DATE) as active_day,
             SUM(value)/COUNT (DISTINCT purchased_at) as basket_value,
             SUM (value)/ SUM (qty) as unit_cost,
             COUNT (DISTINCT product_code) as num_pro,
             COUNT(DISTINCT purchased_at::DATE)/((EXTRACT(day from (MAX(purchased_at)-MIN(purchased_at)))/%(ws)s)::INT+1) AS average_visit,
             SUM (value)/((EXTRACT(day from (MAX(purchased_at)-MIN(purchased_at)))/%(ws)s)::INT+1) AS average_spend
     FROM ml2.receipts_clean
     JOIN ml2.receipt_lines_clean
     USING (receipt_id)
     --below condition to make sure we do not include future data--
     WHERE purchased_at<=%(ref_date)s::date
     --only consider the nearest 5 period
     AND purchased_at>%(ref_date)s::DATE -%(ws)s*5
     GROUP BY customer_id
     HAVING MAX(purchased_at)>%(ref_date)s::DATE-%(ws)s),
             
     --create static value as most frequently visit store--
     store AS (
     SELECT customer_id, store_code 
            FROM (SELECT customer_id, store_code, COUNT(*) AS ct
                    FROM ml2.receipts_clean
                    GROUP BY 1,2)x
            GROUP BY 1,2,ct
            HAVING ct=MAX(ct))
    
    SELECT * FROM tumbling JOIN store USING (customer_id) JOIN rfm USING (customer_id)
    
      """

      df = pd.read_sql(sql, conn, params = {'ref_date':reference_day, 'ws':tumbling_window_size, 'ows':output_window_size})

      return df.drop(columns = ['ref_day','output_feature','customer_id'], inplace = False), df.output_feature

# create processing function includes:
def data_process (X,y):
    for i in range(len(y)):
        # process output to churn/ non churn based on decreasethreshold = 0.49
        if y[i]<=X.iloc[i,-2]*0.49:
            y[i]=1
        else:
            y[i]=0
    # one hot coding process for store inputs
    from sklearn.preprocessing import LabelBinarizer
    lb = LabelBinarizer()
    def binary_convert(df,a):
        lb_results = lb.fit_transform(df[a])
        df_onehot = pd.DataFrame(lb_results, columns=lb.classes_)
        for col in list(df_onehot.columns):
            df_onehot.rename(columns={col:(a+'_'+str(col))},inplace = True)
        df=df.drop(columns=a)
        new_df=pd.concat([df,df_onehot],axis=1)
        return new_df
    X_new=binary_convert(X,'store_code')
    # define X_temp as visit window aggerated feature
    X_temp=X_new.iloc[:,5:10]
    # define X_stat include global aggerated & window aggerated features (exclude spending)
    X_stat=X_new[['visit_f1','visit_f2','visit_f3','visit_f4','visit_f5','active_day','basket_value','unit_cost','num_pro','average_visit']]
    return X_new, X_temp, X_stat, y

# Create a train and test set with reference date gap =38
X_train, y_train  = get_dataset("2020-09-09")
X_train, X_train_temp, X_train_stat, y_train=data_process (X_train,y_train)
X_test, y_test  = get_dataset("2020-10-17")
X_test, X_test_temp, X_test_stat, y_test=data_process (X_test,y_test)

X_train.describe()

y_train.value_counts()

"""## Feature selection

Correlation check - from that exclude store features, spending features (as similar with visit)
"""

# Plot heatmap of inputs with output
all_train=pd.concat([X_train,y_train], axis=1)
corr=pd.DataFrame(all_train.corr()['output_feature'].sort_values(ascending=False))
plt.figure(figsize=(1,7))
g=sns.heatmap(corr[1:],annot=True,cmap="Blues",annot_kws={"size": 8},fmt=".1%")

# Plot heat map for all features
plt.figure(figsize=(50,30))
g=sns.heatmap(all_train.corr(),annot=True,cmap="Blues",annot_kws={"size": 20})

"""Sub-group check
Try baseline model (RF) on 3 feature sets
Using 5 folds of temporal hold-outs
Up to training date (2020-09-09)
"""

# Run RF on all feature set
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score
import datetime  
from datetime import timedelta
import numpy as np
ref_date= datetime.date(2020,9,9)
fold=5
roc_all=[]
acc_all=[]
for k in range(fold):
    ref_test=str(ref_date-timedelta(days=38*k))
    ref_train=str(ref_date-timedelta(days=38*(k+1)))
    X_test, y_test=get_dataset(ref_test)
    X_test, X_test_temp, X_test_stat, y_test=data_process (X_test,y_test)
    X_train, y_train=get_dataset(ref_train)
    X_train, X_train_temp, X_train_stat, y_train=data_process (X_train,y_train)
    rf=RandomForestClassifier(random_state=42, min_samples_leaf=30)
    rf.fit(X_train_stat,y_train)
    y_pred=rf.predict_proba(X_test_stat)[:,1]
    roc_all.append(roc_auc_score(y_test, y_pred))
    acc_all.append(rf.score(X_test_stat,y_test))

# AUC
print(np.mean(roc_all))
#Accurancy
print(np.mean(acc_all))

# Run Dummy on all feature set (try in any model - doesnt matter)
from sklearn.dummy import DummyClassifier
from sklearn.metrics import roc_auc_score
import datetime  
from datetime import timedelta
import numpy as np
ref_date= datetime.date(2020,9,9)
fold=5
roc_all1=[]
acc_all1=[]
for k in range(fold):
    ref_test=str(ref_date-timedelta(days=38*k))
    ref_train=str(ref_date-timedelta(days=38*(k+1)))
    X_test, y_test=get_dataset(ref_test)
    X_test, X_test_temp, X_test_stat, y_test=data_process (X_test,y_test)
    X_train, y_train=get_dataset(ref_train)
    X_train, X_train_temp, X_train_stat, y_train=data_process (X_train,y_train)
    dm=DummyClassifier(random_state=42, strategy='stratified')
    dm.fit(X_train_stat,y_train)
    y_pred=dm.predict_proba(X_test_stat)[:,1]
    roc_all1.append(roc_auc_score(y_test, y_pred))
    acc_all1.append(dm.score(X_test_stat,y_test))

# AUC
print(np.mean(roc_all1))
# Accuracy
print(np.mean(acc_all1))

# Run RF on visit window aggerates set
from sklearn.metrics import roc_auc_score
import datetime  
from datetime import timedelta
import numpy as np
ref_date= datetime.date(2020,9,9)
fold=5
roc_vis=[]
acc_vis=[]
for k in range(fold):
    ref_test=str(ref_date-timedelta(days=38*k))
    ref_train=str(ref_date-timedelta(days=38*(k+1)))
    X_test, y_test=get_dataset(ref_test)
    X_test, X_test_temp, X_test_stat, y_test=data_process (X_test,y_test)
    X_train, y_train=get_dataset(ref_train)
    X_train, X_train_temp, X_train_stat, y_train=data_process (X_train,y_train)
    rf=RandomForestClassifier(random_state=42, min_samples_leaf=30)
    rf.fit(X_train_temp,y_train)
    y_pred=rf.predict_proba(X_test_temp)[:,1]
    roc_vis.append(roc_auc_score(y_test, y_pred))
    acc_vis.append(rf.score(X_test_temp,y_test))

# AUC
print(np.mean(roc_vis))
# Accuracy
print(np.mean(acc_vis))

# Run RF on global aggerates set
from sklearn.metrics import roc_auc_score
import datetime  
from datetime import timedelta
import numpy as np
ref_date= datetime.date(2020,9,9)
fold=5
roc_stat=[]
acc_stat=[]
for k in range(fold):
    ref_test=str(ref_date-timedelta(days=38*k))
    ref_train=str(ref_date-timedelta(days=38*(k+1)))
    X_test, y_test=get_dataset(ref_test)
    X_test, X_test_temp, X_test_stat, y_test=data_process (X_test,y_test)
    X_train, y_train=get_dataset(ref_train)
    X_train, X_train_temp, X_train_stat, y_train=data_process (X_train,y_train)
    rf=RandomForestClassifier(random_state=42, min_samples_leaf=30)
    rf.fit(X_train_stat.drop(columns=['visit_f1','visit_f2','visit_f3','visit_f4','visit_f5']),y_train)
    y_pred=rf.predict_proba(X_test_stat.drop(columns=['visit_f1','visit_f2','visit_f3','visit_f4','visit_f5']))[:,1]
    roc_stat.append(roc_auc_score(y_test, y_pred))
    acc_stat.append(rf.score(X_test_stat.drop(columns=['visit_f1','visit_f2','visit_f3','visit_f4','visit_f5']),y_test))

# AUC
print(np.mean(roc_stat))
# Accuracy
print(np.mean(acc_stat))

"""## Model evluation

Window aggerates - Tuning & Performance on test set
"""

# Tuning RF on window features
from sklearn.metrics import roc_auc_score
import datetime  
from datetime import timedelta
import numpy as np
from sklearn.ensemble import RandomForestClassifier
ref_date= datetime.date(2020,9,9)
n_estimators = list(range(5,100,5))
max_depth=list(range(2,10))
fold=5
best_param={}
for i in n_estimators:
    for j in max_depth:
        roc_temp=[]
        for k in range(fold):         
            ref_test=str(ref_date-timedelta(days=38*k))
            ref_train=str(ref_date-timedelta(days=38*(k+1)))
            X_test, y_test=get_dataset(ref_test)
            X_test, X_test_temp, X_test_stat, y_test=data_process (X_test,y_test)
            X_train, y_train=get_dataset(ref_train)
            X_train, X_train_temp, X_train_stat, y_train=data_process (X_train,y_train)
            rf_temp=RandomForestClassifier(n_estimators=i,max_depth=j, random_state=42, n_jobs=-1)
            rf_temp.fit(X_train_temp,y_train)
            y_pred=rf_temp.predict_proba(X_test_temp)[:,1]
            roc_temp.append(roc_auc_score(y_test, y_pred))
        best_param[str(i)+', '+str(j)]=np.mean(roc_temp)

# Tuning kNN on window features
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import roc_auc_score
from tslearn.metrics import dtw
ref_date= datetime.date(2020,9,9)
n_neighbors = list(range(1,20))
metric=['l1','l2',dtw]
fold=5
best_param1={}
for i in n_neighbors:
    for j in metric:
        roc_temp=[]
        for k in range(fold):         
            ref_test=str(ref_date-timedelta(days=38*k))
            ref_train=str(ref_date-timedelta(days=38*(k+1)))
            X_test, y_test=get_dataset(ref_test)
            X_test, X_test_temp, X_test_stat, y_test=data_process (X_test,y_test)
            X_train, y_train=get_dataset(ref_train)
            X_train, X_train_temp, X_train_stat, y_train=data_process (X_train,y_train)
            knn=KNeighborsClassifier(n_neighbors=i,metric=j, n_jobs=-1)
            knn.fit(X_train_temp,y_train)
            y_pred=knn.predict_proba(X_test_temp)[:, 1]
            roc_temp.append(roc_auc_score(y_test, y_pred))
        best_param1[str(i)+', '+str(j)]=np.mean(roc_temp)

# Best param for RF
sorted_best_param = sorted(best_param.items(), key=lambda kv: kv[1], reverse=True)
sorted_best_param[0]

# Best param for kNN
sorted_best_param1 = sorted(best_param1.items(), key=lambda kv: kv[1], reverse=True)
sorted_best_param1[0]

# Recall data set
X_valid, y_valid  = get_dataset("2020-09-09")
X_valid, X_valid_temp, X_valid_stat, y_valid=data_process (X_valid,y_valid)
X_test, y_test  = get_dataset("2020-10-17")
X_test, X_test_temp, X_test_stat, y_test=data_process (X_test,y_test)

#Tuned RF performance on the test set
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import plot_confusion_matrix
rf_temp=RandomForestClassifier(random_state=42, max_depth=4, n_estimators=95)
rf_temp.fit(X_valid_temp, y_valid)
print(rf_temp.score(X_test_temp, y_test))
plot_confusion_matrix(rf_temp, X=X_test_temp, y_true=y_test, cmap='Blues')

#Tuned kNN performance on the test set
from sklearn.neighbors import KNeighborsClassifier
knn_temp=KNeighborsClassifier(n_neighbors=19, metric='l2', n_jobs=-1)
knn_temp.fit(X_valid_temp, y_valid)
print(knn_temp.score(X_test_temp, y_test))
plot_confusion_matrix(knn_temp, X=X_test_temp, y_true=y_test, cmap='Blues')

#SVC performance on the test set - no pre tuning as highly computational expensive
from tslearn.svm import TimeSeriesSVC
from sklearn.model_selection import GridSearchCV
svc = TimeSeriesSVC(random_state=42, n_jobs=-1)
svc.fit(X_valid_temp,y_valid)
print(svc.score(X_test_temp,y_test))
plot_confusion_matrix(svc, X=X_test_temp, y_true=y_test, values_format='d', cmap='Blues')

"""All features - Tuning & Performance on test set"""

# Tuning RF on all features
ref_date= datetime.date(2020,9,9)
n_estimators = list(range(5,100,5))
max_depth=list(range(2,10))
fold=5
best_param_all_1={}
for i in n_estimators:
    for j in max_depth:
        roc=[]
        for k in range(fold):         
            ref_test=str(ref_date-timedelta(days=38*k))
            ref_train=str(ref_date-timedelta(days=38*(k+1)))
            X_test, y_test=get_dataset(ref_test)
            X_test, X_test_temp, X_test_stat, y_test=data_process (X_test,y_test)
            X_train, y_train=get_dataset(ref_train)
            X_train, X_train_temp, X_train_stat, y_train=data_process (X_train,y_train)
            rf=RandomForestClassifier(n_estimators=i,max_depth=j, random_state=42,n_jobs=-1)
            rf.fit(X_train_stat,y_train)
            y_pred=rf.predict_proba(X_test_stat)[:,1]
            roc.append(roc_auc_score(y_test, y_pred))
        best_param_all_1[str(i)+', '+str(j)]=np.mean(roc)

# Tuning kNN on all features
from sklearn.preprocessing import MinMaxScaler
scl= MinMaxScaler()
from sklearn.metrics import roc_auc_score
ref_date= datetime.date(2020,9,9)
n_neighbors = list(range(1,20))
metric=['l1','l2']
fold=5
best_param_all_2={}
for i in n_neighbors:
    for j in metric:
        roc_temp=[]
        for k in range(fold):         
            ref_test=str(ref_date-timedelta(days=38*k))
            ref_train=str(ref_date-timedelta(days=38*(k+1)))
            X_test, y_test=get_dataset(ref_test)
            X_test, X_test_temp, X_test_stat, y_test=data_process (X_test,y_test)
            X_train, y_train=get_dataset(ref_train)
            X_train, X_train_temp, X_train_stat, y_train=data_process (X_train,y_train)
            knn=KNeighborsClassifier(n_neighbors=i,metric=j, n_jobs=-1)
            knn.fit(scl.fit_transform(X_train_stat),y_train)
            y_pred=knn.predict_proba(scl.fit_transform(X_test_stat))[:, 1]
            roc_temp.append(roc_auc_score(y_test, y_pred))
        best_param_all_2[str(i)+', '+str(j)]=np.mean(roc_temp)

# Tuning DT on all features
from sklearn.tree import DecisionTreeClassifier
ref_date= datetime.date(2020,9,9)
min_samples_leaf = list(range(5,100,5))
max_depth=list(range(2,10))
fold=5
best_param_all_3={}
for i in min_samples_leaf:
    for j in max_depth:
        roc_temp=[]
        for k in range(fold):         
            ref_test=str(ref_date-timedelta(days=38*k))
            ref_train=str(ref_date-timedelta(days=38*(k+1)))
            X_test, y_test=get_dataset(ref_test)
            X_test, X_test_temp, X_test_stat, y_test=data_process (X_test,y_test)
            X_train, y_train=get_dataset(ref_train)
            X_train, X_train_temp, X_train_stat, y_train=data_process (X_train,y_train)
            dt=DecisionTreeClassifier(min_samples_leaf=i,max_depth=j, random_state=42)
            dt.fit(X_train_stat,y_train)
            y_pred=dt.predict_proba(X_test_stat)[:,1]
            roc_temp.append(roc_auc_score(y_test, y_pred))
        best_param_all_3[str(i)+', '+str(j)]=np.mean(roc_temp)

# Tuning LR on all features
from sklearn.linear_model import LogisticRegression
ref_date= datetime.date(2020,9,9)
C=[0.001,0.01,0.1,1.0,10,100]
fold=5
best_param_all_4={}
for j in C:
    roc_temp=[]
    for k in range(fold):         
        ref_test=str(ref_date-timedelta(days=38*k))
        ref_train=str(ref_date-timedelta(days=38*(k+1)))
        X_test, y_test=get_dataset(ref_test)
        X_test, X_test_temp, X_test_stat, y_test=data_process (X_test,y_test)
        X_train, y_train=get_dataset(ref_train)
        X_train, X_train_temp, X_train_stat, y_train=data_process (X_train,y_train)
        lr=LogisticRegression(C=j, random_state=42, n_jobs=-1)
        lr.fit(X_train_stat,y_train)
        y_pred=lr.predict_proba(X_test_stat)[:,1]
        roc_temp.append(roc_auc_score(y_test, y_pred))
    best_param_all_4[str(j)]=np.mean(roc_temp)

# sorted results
sorted_param_all_1 = sorted(best_param_all_1.items(), key=lambda kv: kv[1], reverse=True)
sorted_param_all_2 = sorted(best_param_all_2.items(), key=lambda kv: kv[1], reverse=True)
sorted_param_all_3 = sorted(best_param_all_3.items(), key=lambda kv: kv[1], reverse=True)
sorted_param_all_4 = sorted(best_param_all_4.items(), key=lambda kv: kv[1], reverse=True)

# Param for RF
sorted_param_all_1[0]

# Param for kNN scaled
sorted_param_all_2[0]

# Param for DT
sorted_param_all_3[0]

# Param for LR
sorted_param_all_4[0]

#Retake the data
X_valid, y_valid  = get_dataset("2020-09-09")
X_valid, X_valid_temp, X_valid_stat, y_valid=data_process (X_valid,y_valid)
X_test, y_test  = get_dataset("2020-10-17")
X_test, X_test_temp, X_test_stat, y_test=data_process (X_test,y_test)

# Tuned RF performance on the test set
from sklearn.metrics import plot_confusion_matrix
rf_all=RandomForestClassifier(random_state=42, max_depth=3, n_estimators=50)
rf_all.fit(X_valid_stat, y_valid)
print(rf_all.score(X_test_stat, y_test))
plot_confusion_matrix(rf_all, X=X_test_stat, y_true=y_test, cmap='Blues')

# Tuned scaled kNN performance on the test set
from sklearn.preprocessing import MinMaxScaler
scl=MinMaxScaler()
from sklearn.metrics import plot_confusion_matrix
knn_all_scl=KNeighborsClassifier(n_neighbors=18, metric='l1')
knn_all_scl.fit(scl.fit_transform(X_valid_stat), y_valid)
print(knn_all_scl.score(scl.fit_transform(X_test_stat), y_test))
plot_confusion_matrix(knn_all_scl, X=scl.fit_transform(X_test_stat), y_true=y_test, cmap='Blues')

# Tuned DT performance on the test set
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import plot_confusion_matrix
dt_all=DecisionTreeClassifier(max_depth=5, min_samples_leaf=70)
dt_all.fit(X_valid_stat, y_valid)
print(dt_all.score(X_test_stat, y_test))
plot_confusion_matrix(dt_all, X=X_test_stat, y_true=y_test, cmap='Blues')

# Tuned LR performance on the test set
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import plot_confusion_matrix
lr_all=LogisticRegression(C=0.001, random_state=42)
lr_all.fit(X_valid_stat, y_valid)
print(lr_all.score(X_test_stat, y_test))
plot_confusion_matrix(lr_all, X=X_test_stat, y_true=y_test, cmap='Blues')

# Plot ROC for all models in test set
from sklearn.metrics import plot_roc_curve
plot_roc_curve(knn_all_scl, scl.fit_transform(X_test_stat),y_test, ax=plt.gca(),name = 'knn_all_scaled')
plot_roc_curve(rf_all, X_test_stat,y_test, ax=plt.gca(),name = 'rf_all')
plot_roc_curve(dt_all, X_test_stat,y_test, ax=plt.gca(),name = 'dt_all')
plot_roc_curve(lr_all, X_test_stat,y_test, ax=plt.gca(),name = 'lr_all')
plot_roc_curve(knn_temp, X_test_temp,y_test, ax=plt.gca(),name = 'knn_temp')
plot_roc_curve(rf_temp, X_test_temp,y_test, ax=plt.gca(),name = 'rf_temp')
plot_roc_curve(svc, X_test_temp,y_test, response_method='decision_function',ax=plt.gca(),name = 'svc_temp')
plt.legend(bbox_to_anchor=(1, 1))

# Calculate AUC for all models in test set
from sklearn.metrics import roc_auc_score
print(roc_auc_score(y_test,knn_all_scl.predict_proba(scl.fit_transform(X_test_stat))[:,1]))
print(roc_auc_score(y_test,rf_all.predict_proba(X_test_stat)[:,1]))
print(roc_auc_score(y_test,dt_all.predict_proba(X_test_stat)[:,1]))
print(roc_auc_score(y_test,lr_all.predict_proba(X_test_stat)[:,1]))
print(roc_auc_score(y_test, knn_temp.predict_proba(X_test_temp)[:,1]))
print(roc_auc_score(y_test, rf_temp.predict_proba(X_test_temp)[:,1]))
print(roc_auc_score(y_test, svc.decision_function(X_test_temp)))

"""Final evaluation between RF in window aggerates set and all set"""

# Tuned RF performance in all set - 10 folds validation
from sklearn.metrics import roc_auc_score
import datetime  
from datetime import timedelta
import numpy as np
ref_date= datetime.date(2020,10,17)
fold=10
roc_all2=[]
acc_all2=[]
for k in range(fold):
    ref_test=str(ref_date-timedelta(days=38*k))
    ref_train=str(ref_date-timedelta(days=38*(k+1)))
    X_test, y_test=get_dataset(ref_test)
    X_test, X_test_temp, X_test_stat, y_test=data_process (X_test,y_test)
    X_train, y_train=get_dataset(ref_train)
    X_train, X_train_temp, X_train_stat, y_train=data_process (X_train,y_train)
    rf=RandomForestClassifier(random_state=42, max_depth=3, n_estimators=50)
    rf.fit(X_train_stat,y_train)
    y_pred=rf.predict_proba(X_test_stat)[:,1]
    roc_all2.append(roc_auc_score(y_test, y_pred))
    acc_all2.append(rf.score(X_test_stat,y_test))

# Tuned RF performance in window set - 10 folds validation
from sklearn.metrics import roc_auc_score
import datetime  
from datetime import timedelta
import numpy as np
ref_date= datetime.date(2020,10,17)
fold=10
roc_all3=[]
acc_all3=[]
for k in range(fold):
    ref_test=str(ref_date-timedelta(days=38*k))
    ref_train=str(ref_date-timedelta(days=38*(k+1)))
    X_test, y_test=get_dataset(ref_test)
    X_test, X_test_temp, X_test_stat, y_test=data_process (X_test,y_test)
    X_train, y_train=get_dataset(ref_train)
    X_train, X_train_temp, X_train_stat, y_train=data_process (X_train,y_train)
    rf=RandomForestClassifier(random_state=42, max_depth=4, n_estimators=95)
    rf.fit(X_train_temp, y_train)
    y_pred=rf.predict_proba(X_test_temp)[:,1]
    roc_all3.append(roc_auc_score(y_test, y_pred))
    acc_all3.append(rf.score(X_test_temp,y_test))

# join AUC and accuracy in one table
compare=pd.DataFrame()
compare['all_acc']=acc_all2
compare['temp_acc']=acc_all3
compare['all_auc']=roc_all2
compare['temp_auc']=roc_all3
compare

# plot result's distribution
fig = plt.figure(figsize=(10, 7))
ax = fig.add_subplot(111)
medianprops = dict(linestyle='-', linewidth=2.5, color='royalblue')
plt.boxplot(compare, medianprops = medianprops)
ax.set_xticklabels(compare.columns)
plt.xticks(rotation=0, horizontalalignment="center")
plt.yticks(rotation=0, horizontalalignment="right")
plt.show()

"""Feature importance"""

# Recall the data
X_valid, y_valid  = get_dataset("2020-09-09")
X_valid, X_valid_temp, X_valid_stat, y_valid=data_process (X_valid,y_valid)
X_test, y_test  = get_dataset("2020-10-17")
X_test, X_test_temp, X_test_stat, y_test=data_process (X_test,y_test)
# Calculate SHAP value to derive feature importance
from sklearn.ensemble import RandomForestClassifier
import shap
rf=RandomForestClassifier(random_state=42, max_depth=3, n_estimators=50)
rf.fit(X_valid_stat,y_valid)
explainer = shap.TreeExplainer(rf, random_state=42)
shap_values = explainer.shap_values(X_valid_stat)
shap.summary_plot(shap_values[1], X_valid_stat)

"""## Insight report"""

# Fit model to latest data
X_valid, y_valid  = get_dataset("2020-10-17")
X_valid, X_valid_temp, X_valid_stat, y_valid=data_process (X_valid,y_valid)
X_test, y_test  = get_dataset("2020-11-24")
X_test, X_test_temp, X_test_stat, y_test=data_process (X_test,y_test)
from sklearn.ensemble import RandomForestClassifier
rf=RandomForestClassifier(random_state=42, max_depth=3, n_estimators=50)
rf.fit(X_valid_stat,y_valid)

"""Churn - Non churn profile"""

# Get the predict probability and prediction at threhold 0.5
# Join prediction with X_test in one table
predict_percent=pd.DataFrame(rf.predict_proba(X_test_stat))[1]
predict_label=pd.DataFrame(rf.predict(X_test_stat))
df=pd.concat([X_test,predict_percent,predict_label],axis=1)

# Rename the columns
df.rename(columns={1:'churn_percent'},inplace=True)
df.rename(columns={0:'churn_label'},inplace=True)
# Rename the prediction result to churn - non churn
for i in range(len(df)):
    if df['churn_label'][i]==1:
        df['churn_label'][i]='Churn'
    else:
        df['churn_label'][i]='Non_churn'

# Group all values to churn - non churn group
pd.set_option('display.max_columns', None)
for c,d in df.groupby('churn_label'):
    print (c)
    print('% size ',len(d)/len(df)*100)
    print ('% sale: ',np.sum(d['total_spend'])/np.sum(df['total_spend'])*100)
    display(d.describe())

#Churn versus non churn profile
#Polar chart for shopping behaviours for each group
!pip install plotly
from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()
key=df.drop(columns=['churn_percent'])
key_standard=pd.DataFrame(scaler.fit_transform(key.iloc[:,5:21]))
for i in range(len(key_standard.columns)):
  key_standard.rename(columns={key_standard.columns[i]:key.iloc[:,5:21].columns[i]},inplace=True)
key_standard=pd.concat([key_standard,pd.DataFrame(key['churn_label'])],axis=1)
import plotly.express as px
polar=key_standard.groupby('churn_label').mean().reset_index()
polar=pd.melt(polar,id_vars=['churn_label'])
fig = px.line_polar(polar, r="value", theta="variable", color="churn_label", line_close=True,
                    color_discrete_map={'Non_churn': "royalblue ",
                                        'Churn': "orangered"})
fig.show()

"""Churn ranking priority"""

# Create ranking columns based on prediction probability
# 1: >=90# ... 10:<10%
df['ranking']=((1-df['churn_percent'])*100)//10+1

# Group all features based on prioritised group (1-9)
for c, d in df.groupby('ranking'):
    print (c)
    print('% size ',len(d)/len(df)*100)
    print ('% sale: ',np.sum(d['total_spend'])/np.sum(df['total_spend'])*100)
    display(d.describe())

# plot count of each group
sns.countplot(data=df, x='ranking',palette='RdBu')

# plot total spend of each group
sns.barplot(data=df, x='ranking',y='total_spend',palette='RdBu')

# plot active day of each group
sns.barplot(data=df, x='ranking',y='active_day',palette='RdBu')

# plot unit cost of each group
sns.barplot(data=df, x='ranking',y='unit_cost',palette='RdBu')

# plot number of products of each group
sns.barplot(data=df, x='ranking',y='num_pro',palette='RdBu')

# plot basket value of each group
sns.barplot(data=df, x='ranking',y='basket_value',palette='RdBu')

#Polar chart for shopping behaviours by group
!pip install plotly
from sklearn.preprocessing import StandardScaler
scaler=StandardScaler()
key=df.drop(columns=['churn_label'])
key_standard=pd.DataFrame(scaler.fit_transform(key.iloc[:,10:21]))
for i in range(len(key_standard.columns)):
  key_standard.rename(columns={key_standard.columns[i]:key.iloc[:,10:21].columns[i]},inplace=True)
key_standard=pd.concat([key_standard,pd.DataFrame(key['ranking'])],axis=1)
key_standard.describe()
import plotly.express as px
polar=key_standard.groupby('ranking').mean().reset_index()
polar=pd.melt(polar,id_vars=['ranking'])
fig = px.line_polar(polar, r="value", theta="variable", color="ranking", line_close=True)
fig.show()

